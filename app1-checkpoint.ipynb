{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e36dd5fd-6d92-4a0e-a7e7-0fd96f12afc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app1.py\n",
    "import streamlit as st\n",
    "import pdfplumber\n",
    "import docx\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ðŸ“„ Extract text from PDF using pdfplumber\n",
    "def extract_text_pdf(file):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or \"\"\n",
    "    return text\n",
    "\n",
    "# ðŸ“„ Extract text from DOCX\n",
    "def extract_text_docx(file):\n",
    "    doc = docx.Document(file)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "# ðŸ§¹ Basic text preprocessing without NLTK\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# â˜ Generate Word Cloud\n",
    "def show_wordcloud(tokens):\n",
    "    wc = WordCloud(width=800, height=400, background_color='white').generate(\" \".join(tokens))\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(wc, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# ðŸ“Š Word Frequency Bar Graph\n",
    "def show_frequency(tokens):\n",
    "    freq = Counter(tokens).most_common(20)\n",
    "    words, counts = zip(*freq)\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    sns.barplot(x=list(words), y=list(counts), palette='viridis', ax=ax)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# ðŸ¥§ Pie Chart of Word Frequency\n",
    "def show_piechart(tokens):\n",
    "    freq = Counter(tokens).most_common(10)  # Top 10 words\n",
    "    words, counts = zip(*freq)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.pie(counts, labels=words, autopct='%1.1f%%', startangle=140)\n",
    "    ax.set_title(\"Top 10 Word Distribution\")\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# ðŸ”¥ Heatmap of Word Co-occurrence\n",
    "def show_heatmap(tokens, window_size=5):\n",
    "    top_words = [word for word, _ in Counter(tokens).most_common(20)]\n",
    "    matrix = np.zeros((20, 20))\n",
    "    for i, word1 in enumerate(top_words):\n",
    "        for j, word2 in enumerate(top_words):\n",
    "            count = sum(1 for k in range(len(tokens) - window_size)\n",
    "                        if word1 in tokens[k:k+window_size] and word2 in tokens[k:k+window_size])\n",
    "            matrix[i][j] = count\n",
    "    df = pd.DataFrame(matrix, index=top_words, columns=top_words)\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(df, cmap='YlGnBu', annot=True, ax=ax)\n",
    "    st.pyplot(fig)\n",
    "\n",
    "# ðŸš€ Streamlit UI\n",
    "st.title(\"ðŸ“š Text Visualization App\")\n",
    "uploaded_file = st.file_uploader(\"Upload PDF or DOCX\", type=[\"pdf\", \"docx\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    if uploaded_file.name.endswith(\".pdf\"):\n",
    "        raw_text = extract_text_pdf(uploaded_file)\n",
    "    else:\n",
    "        raw_text = extract_text_docx(uploaded_file)\n",
    "\n",
    "    st.subheader(\"Extracted Text Preview\")\n",
    "    st.write(raw_text[:1000] + \"...\")  # Show preview\n",
    "\n",
    "    tokens = preprocess_text(raw_text)\n",
    "\n",
    "    if not tokens:\n",
    "        st.warning(\"No text found in the uploaded document.\")\n",
    "    else:\n",
    "        option = st.selectbox(\"Choose Visualization\", [\"Word Cloud\", \"Word Frequency\", \"Pie Chart\", \"Heatmap\"])\n",
    "\n",
    "        if option == \"Word Cloud\":\n",
    "            show_wordcloud(tokens)\n",
    "        elif option == \"Word Frequency\":\n",
    "            show_frequency(tokens)\n",
    "        elif option == \"Pie Chart\":\n",
    "            show_piechart(tokens)\n",
    "        elif option == \"Heatmap\":\n",
    "            show_heatmap(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79f82722-3b57-41d4-92e1-38161d815e40",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3737097518.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    streamlit run app.py\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2cdb2a6-7b40-4f01-acb3-32a1860322b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx in c:\\users\\konda\\onedrive\\pictures\\anaconda\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: lxml in c:\\users\\konda\\onedrive\\pictures\\anaconda\\lib\\site-packages (from docx) (5.2.1)\n",
      "Requirement already satisfied: Pillow>=2.0 in c:\\users\\konda\\onedrive\\pictures\\anaconda\\lib\\site-packages (from docx) (10.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8382463-a2a0-4b49-b756-96121c39e949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce5882e-bf62-4c69-b60e-d3c1a863a0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\konda\\onedrive\\pictures\\anaconda\\lib\\site-packages (from python-docx) (5.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\konda\\onedrive\\pictures\\anaconda\\lib\\site-packages (from python-docx) (4.11.0)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Installing collected packages: python-docx\n",
      "Successfully installed python-docx-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b5bae-3848-4704-a8f2-dd46d43b9085",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
